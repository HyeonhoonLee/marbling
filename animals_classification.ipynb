{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "animals_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "14Sb_68Mqq5TJ0wTxC0hAAiKiMCixWZCF",
      "authorship_tag": "ABX9TyOFWbQhueP4z1dauj2V+NSE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HyeonhoonLee/marbling/blob/master/animals_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9I8ms5JGNnKF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPpdQC9xNjys",
        "colab_type": "text"
      },
      "source": [
        "**Classifying either beaver, panda, Leopards, or dalmatian**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojfCkrCuNjW5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b6795cf7-64af-456d-d8a7-eed4934c29fe"
      },
      "source": [
        "from PIL import Image\n",
        "import os, glob\n",
        "import numpy as np\n",
        "import random, math\n",
        "# 분류 대상 카테고리\n",
        "root_dir = \"/content/drive/My Drive/WikiExample/ch7/image/101_ObjectCategories\"\n",
        "categories = [\"beaver\", \"panda\", \"Leopards\", \"dalmatian\"]\n",
        "nb_classes = len(categories)\n",
        "image_size = 50\n",
        "# 이미지 데이터 읽어 들이기 --- (※1)\n",
        "X = [] # 이미지 데이터\n",
        "Y = [] # 레이블 데이터\n",
        "def add_sample(cat, fname, is_train):\n",
        "    img = Image.open(fname)\n",
        "    img = img.convert(\"RGB\") # 색상 모드 변경하기\n",
        "    img = img.resize((image_size, image_size)) # 이미지 크기 변경하기\n",
        "    data = np.asarray(img)\n",
        "    X.append(data)\n",
        "    Y.append(cat)\n",
        "    if not is_train: return\n",
        "    # 각도를 조금 변경한 파일 추가하기\n",
        "    # 회전하기\n",
        "    for ang in range(-20, 20, 5):\n",
        "        img2 = img.rotate(ang)\n",
        "        data = np.asarray(img2)\n",
        "        X.append(data)\n",
        "        Y.append(cat)\n",
        "        # img2.save(\"gyudon-\"+str(ang)+\".PNG\")\n",
        "        # 반전하기\n",
        "        img2 = img2.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "        data = np.asarray(img2)\n",
        "        X.append(data)\n",
        "        Y.append(cat)\n",
        "def make_sample(files, is_train):\n",
        "    global X, Y\n",
        "    X = []; Y = []\n",
        "    for cat, fname in files:\n",
        "        add_sample(cat, fname, is_train)\n",
        "    return np.array(X), np.array(Y)\n",
        "# 각 폴더에 들어있는 파일 수집하기 --- (※2)\n",
        "allfiles = []\n",
        "for idx, cat in enumerate(categories):\n",
        "    image_dir = root_dir + \"/\" + cat\n",
        "    files = glob.glob(image_dir + \"/*.jpg\")\n",
        "    for f in files:\n",
        "        allfiles.append((idx, f))\n",
        "# 섞은 뒤에 학습 전용 데이터와 테스트 전용 데이터 구분하기 --- (※3)\n",
        "random.shuffle(allfiles)\n",
        "th = math.floor(len(allfiles) * 0.6)\n",
        "train = allfiles[0:th]\n",
        "test  = allfiles[th:]\n",
        "X_train, y_train = make_sample(train, True)\n",
        "X_test, y_test = make_sample(test, False)\n",
        "xy = (X_train, X_test, y_train, y_test)\n",
        "np.save(\"/content/drive/My Drive/WikiExample/ch7/image/animals.npy\", xy)\n",
        "print(\"ok,\", len(y_train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ok, 3570\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9xae69ZpaUS",
        "colab_type": "text"
      },
      "source": [
        "#Training with CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1PMFfxFJsDg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cd92f572-1203-4722-d1a4-1045abb83c6a"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras.utils import np_utils\n",
        "import numpy as np\n",
        "# 분류 대상 카테고리\n",
        "root_dir = \"/content/drive/My Drive/WikiExample/ch7/image/101_ObjectCategories\"\n",
        "categories = [\"beaver\", \"panda\", \"Leopards\", \"dalmatian\"]\n",
        "nb_classes = len(categories)\n",
        "image_size = 50\n",
        "# 데이터 다운로드하기 --- (※1)\n",
        "def main():\n",
        "    X_train, X_test, y_train, y_test = np.load(\"/content/drive/My Drive/WikiExample/ch7/image/animals.npy\",allow_pickle=True)\n",
        "    # 데이터 정규화하기\n",
        "    X_train = X_train.astype(\"float\") / 256\n",
        "    X_test  = X_test.astype(\"float\")  / 256\n",
        "    y_train = np_utils.to_categorical(y_train, nb_classes)\n",
        "    y_test  = np_utils.to_categorical(y_test, nb_classes)\n",
        "    # 모델을 훈련하고 평가하기\n",
        "    model = model_train(X_train, y_train)\n",
        "    model_eval(model, X_test, y_test)\n",
        "# 모델 구축하기 --- (※2)\n",
        "def build_model(in_shape):\n",
        "    model = Sequential()\n",
        "    model.add(Convolution2D(32, 3, 3, \n",
        "        border_mode='same',\n",
        "        input_shape=in_shape))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Convolution2D(64, 3, 3, border_mode='same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Convolution2D(64, 3, 3))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Flatten()) \n",
        "    model.add(Dense(512))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(nb_classes))\n",
        "    model.add(Activation('softmax'))\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "        optimizer='rmsprop',\n",
        "        metrics=['accuracy'])\n",
        "    return model\n",
        "# 모델 훈련하기 --- (※3)\n",
        "def model_train(X, y):\n",
        "    model = build_model(X.shape[1:])\n",
        "    model.fit(X, y, batch_size=32, nb_epoch=30)\n",
        "    # 모델 저장하기 --- (※4)\n",
        "    hdf5_file = \"/content/drive/My Drive/WikiExample/ch7/image/animlas-model.hdf5\"\n",
        "    model.save_weights(hdf5_file)\n",
        "    return model\n",
        "# 모델 평가하기 --- (※5)\n",
        "def model_eval(model, X, y):\n",
        "    score = model.evaluate(X, y)\n",
        "    print('loss=', score[0])\n",
        "    print('accuracy=', score[1])\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:30: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(50, 50, 3..., padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:34: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:36: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3))`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:52: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "3570/3570 [==============================] - 8s 2ms/step - loss: 0.4079 - accuracy: 0.8678\n",
            "Epoch 2/30\n",
            "3570/3570 [==============================] - 2s 557us/step - loss: 0.1056 - accuracy: 0.9612\n",
            "Epoch 3/30\n",
            "3570/3570 [==============================] - 2s 588us/step - loss: 0.0393 - accuracy: 0.9879\n",
            "Epoch 4/30\n",
            "3570/3570 [==============================] - 2s 598us/step - loss: 0.0319 - accuracy: 0.9907\n",
            "Epoch 5/30\n",
            "3570/3570 [==============================] - 2s 579us/step - loss: 0.0233 - accuracy: 0.9936\n",
            "Epoch 6/30\n",
            "3570/3570 [==============================] - 2s 571us/step - loss: 0.0179 - accuracy: 0.9955\n",
            "Epoch 7/30\n",
            "3570/3570 [==============================] - 2s 599us/step - loss: 0.0177 - accuracy: 0.9961\n",
            "Epoch 8/30\n",
            "3570/3570 [==============================] - 2s 555us/step - loss: 0.0207 - accuracy: 0.9954\n",
            "Epoch 9/30\n",
            "3570/3570 [==============================] - 2s 561us/step - loss: 0.0162 - accuracy: 0.9964\n",
            "Epoch 10/30\n",
            "3570/3570 [==============================] - 2s 570us/step - loss: 0.0170 - accuracy: 0.9966\n",
            "Epoch 11/30\n",
            "3570/3570 [==============================] - 2s 565us/step - loss: 0.0276 - accuracy: 0.9958\n",
            "Epoch 12/30\n",
            "3570/3570 [==============================] - 2s 579us/step - loss: 0.0077 - accuracy: 0.9978\n",
            "Epoch 13/30\n",
            "3570/3570 [==============================] - 2s 593us/step - loss: 0.0190 - accuracy: 0.9973\n",
            "Epoch 14/30\n",
            "3570/3570 [==============================] - 2s 631us/step - loss: 0.0138 - accuracy: 0.9973\n",
            "Epoch 15/30\n",
            "3570/3570 [==============================] - 2s 635us/step - loss: 0.0091 - accuracy: 0.9982\n",
            "Epoch 16/30\n",
            "3570/3570 [==============================] - 2s 631us/step - loss: 0.0101 - accuracy: 0.9980\n",
            "Epoch 17/30\n",
            "3570/3570 [==============================] - 2s 603us/step - loss: 0.0179 - accuracy: 0.9982\n",
            "Epoch 18/30\n",
            "3570/3570 [==============================] - 2s 598us/step - loss: 0.0222 - accuracy: 0.9971\n",
            "Epoch 19/30\n",
            "3570/3570 [==============================] - 2s 604us/step - loss: 0.0230 - accuracy: 0.9972\n",
            "Epoch 20/30\n",
            "3570/3570 [==============================] - 2s 612us/step - loss: 0.0081 - accuracy: 0.9987\n",
            "Epoch 21/30\n",
            "3570/3570 [==============================] - 2s 605us/step - loss: 0.0079 - accuracy: 0.9989\n",
            "Epoch 22/30\n",
            "3570/3570 [==============================] - 2s 604us/step - loss: 0.0157 - accuracy: 0.9971\n",
            "Epoch 23/30\n",
            "3570/3570 [==============================] - 2s 605us/step - loss: 0.0112 - accuracy: 0.9979\n",
            "Epoch 24/30\n",
            "3570/3570 [==============================] - 2s 602us/step - loss: 0.0018 - accuracy: 0.9996\n",
            "Epoch 25/30\n",
            "3570/3570 [==============================] - 2s 598us/step - loss: 0.0250 - accuracy: 0.9965\n",
            "Epoch 26/30\n",
            "3570/3570 [==============================] - 2s 569us/step - loss: 0.0198 - accuracy: 0.9974\n",
            "Epoch 27/30\n",
            "3570/3570 [==============================] - 2s 571us/step - loss: 0.0138 - accuracy: 0.9987\n",
            "Epoch 28/30\n",
            "3570/3570 [==============================] - 2s 573us/step - loss: 0.0137 - accuracy: 0.9982\n",
            "Epoch 29/30\n",
            "3570/3570 [==============================] - 2s 572us/step - loss: 0.0167 - accuracy: 0.9986\n",
            "Epoch 30/30\n",
            "3570/3570 [==============================] - 2s 569us/step - loss: 0.0218 - accuracy: 0.9975\n",
            "141/141 [==============================] - 0s 915us/step\n",
            "loss= 0.5923304955164591\n",
            "accuracy= 0.9468085169792175\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7A-yqD1Sm3G",
        "colab_type": "text"
      },
      "source": [
        "#명령줄로 이미지 판정할 수 있게 하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMKHTxzRZJ8a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/WikiExample/ch7/test\")\n",
        "#[출처] [구글 코랩] GOOGLE COLAB 파일 호출하기|작성자 러닝머신"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIf1oLqiVTaZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "outputId": "a2fb077e-0a92-4255-8228-64186d43f445"
      },
      "source": [
        "import animals_keras as animals\n",
        "import sys, os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "# 명령줄에서 파일 이름 지정하기 --- (※1)\n",
        "if len(sys.argv) <= 1:\n",
        "    print(\"animal-checker.py (<파일 이름>)\")\n",
        "    quit()\n",
        "image_size = 50\n",
        "categories = [\n",
        "    \"beaver\", \"panda\", \"Leopards\", \"dalmatian\"]\n",
        "\n",
        "# 입력 이미지를 Numpy로 변환하기 --- (※2)\n",
        "X = []\n",
        "files = []\n",
        "for fname in sys.argv[1:]:\n",
        "    img = Image.open(fname)\n",
        "    img = img.convert(\"RGB\")\n",
        "    img = img.resize((image_size, image_size))\n",
        "    in_data = np.asarray(img)\n",
        "    X.append(in_data)\n",
        "    files.append(fname)\n",
        "X = np.array(X)\n",
        "# CNN 모델 구축하기 --- (※3)\n",
        "model = animals.build_model(X.shape[1:])\n",
        "model.load_weights(\"/content/drive/My Drive/WikiExample/ch7/image/animlas-model.hdf5\")\n",
        "# 데이터 예측하기 --- (※4)\n",
        "html = \"\"\n",
        "pre = model.predict(X)\n",
        "for i, p in enumerate(pre):\n",
        "    y = p.argmax()\n",
        "    print(\"+입력:\", files[i])\n",
        "    print(\"|동물 이름:\", categories[y])\n",
        "    html += \"\"\"\n",
        "        <h3>입력:{0}</h3>\n",
        "        <div>\n",
        "          <p><img src=\"{1}\" width=300></p>\n",
        "          <p>규동 이름:{2}</p>\n",
        "        </div>\n",
        "    \"\"\".format(os.path.basename(files[i]),\n",
        "        files[i],\n",
        "        categories[y])\n",
        "# 리포트 저장하기 --- (※5)\n",
        "html = \"<html><body style='text-align:center;'>\" + \\\n",
        "    \"<style> p { margin:0; padding:0; } </style>\" + \\\n",
        "    html + \"</body></html>\"\n",
        "with open(\"animlas-result.html\", \"w\") as f:\n",
        "    f.write(html)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-0543b43f5566>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2808\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2809\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2810\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '-f'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpHGnVagpgNP",
        "colab_type": "text"
      },
      "source": [
        "#명령줄에서 실행"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-8ahdDpe54W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "outputId": "53482adb-427c-4a61-e950-8d8a994a6611"
      },
      "source": [
        "! python animals-checker.py pan.jpg dalma.jpg pan1.jpg beav.jpg leo.jpg beav1.jpg"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-07-26 09:53:46.117413: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "Using TensorFlow backend.\n",
            "/content/drive/My Drive/WikiExample/ch7/test/animals_keras.py:39: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(50, 50, 3..., padding=\"same\")`\n",
            "  input_shape=in_shape))\n",
            "2020-07-26 09:53:48.705311: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-07-26 09:53:48.708312: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2020-07-26 09:53:48.708353: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (028c735b5c0b): /proc/driver/nvidia/version does not exist\n",
            "2020-07-26 09:53:48.713681: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2300000000 Hz\n",
            "2020-07-26 09:53:48.713945: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1e67100 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-07-26 09:53:48.713980: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "/content/drive/My Drive/WikiExample/ch7/test/animals_keras.py:43: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\")`\n",
            "  model.add(Convolution2D(64, 3, 3, border_mode='same'))\n",
            "/content/drive/My Drive/WikiExample/ch7/test/animals_keras.py:45: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3))`\n",
            "  model.add(Convolution2D(64, 3, 3))\n",
            "+입력: pan.jpg\n",
            "|동물 이름: dalmatian\n",
            "+입력: dalma.jpg\n",
            "|동물 이름: dalmatian\n",
            "+입력: pan1.jpg\n",
            "|동물 이름: panda\n",
            "+입력: beav.jpg\n",
            "|동물 이름: dalmatian\n",
            "+입력: leo.jpg\n",
            "|동물 이름: Leopards\n",
            "+입력: beav1.jpg\n",
            "|동물 이름: beaver\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}